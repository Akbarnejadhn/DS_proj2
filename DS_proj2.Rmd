---
title: "DS_proj2"
author: "Hana Akbarnejad"
date: "3/16/2020"
output: html_document
---

```{r setup, include=FALSE}

library(tidyverse)
library(viridis)
library(ggplot2)
library(readr)
library(caret)
library(splines)
library(mgcv)
library(pdp)
library(earth)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

```{r data}

# excluding Columbia University from Data
college_data = read_csv("College.csv") %>% 
  janitor::clean_names() %>% 
  filter(college != "Columbia University") %>% 
  select(-college) %>% 
  select(outstate, everything())

# defining model matrix of response variables and y(outstate tuition)
x = model.matrix(outstate~.,college_data)[,-1]
y = college_data$outstate
control = trainControl(method = "cv", number = 5)
```

### Part a

In this part, I will create scatter plots to show the relationship between reponse variable and covariates. I used *featureplot* from *caret package* to do this.
```{r part_a}

#scatterplot
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)
featurePlot(x, y, plot = "scatter", labels = c("","Y"),
type = c("p"), layout = c(4, 4))
```

describe the results......................

### Part b

In this part I will fit a **smoothing spline model** using *terminal* as the only predictor and *outstate* as the outcome.

For the degrees of freedom, I will use two methods and plot the resulting fits:

* Using generalized cross-validation (GCV) to obtain degrees of freedom


* Using a range of degrees of freedom

```{r}

# df using GCV
ss_fit = smooth.spline(college_data$terminal, college_data$outstate)
ss_fit

ss_fit$df

# plotting the ss fit
terminal_lims = range(college_data$terminal)
terminal_grid = seq(from = terminal_lims[1],to = terminal_lims[2])

ss_fit2 = smooth.spline(college_data$terminal, college_data$outstate, df = 2)
ss_fit2
ss_pred2 = predict(ss_fit2, x = terminal_grid)
ss_pred_df2 = data.frame(pred = ss_pred2$y, terminal = terminal_grid)


ss_fit6 = smooth.spline(college_data$terminal, college_data$outstate, df = 6)
ss_fit6
ss_pred6 = predict(ss_fit6, x = terminal_grid)
ss_pred_df6 = data.frame(pred = ss_pred6$y, terminal = terminal_grid)


ss_fit10 = smooth.spline(college_data$terminal, college_data$outstate, df = 10)
ss_fit10
ss_pred10 = predict(ss_fit10, x = terminal_grid)
ss_pred_df10 = data.frame(pred = ss_pred10$y, terminal = terminal_grid)

ss_fit20 = smooth.spline(college_data$terminal, college_data$outstate, df = 20)
ss_fit20
ss_pred20 = predict(ss_fit20, x = terminal_grid)
ss_pred_df20 = data.frame(pred = ss_pred20$y, terminal = terminal_grid)

# plotting

ggplot(data = college_data, aes(x = terminal, y = outstate)) +
geom_point(color = rgb(.2, .4, .2, .5)) +
  
    geom_line(aes(x = terminal, y = pred), data = ss_pred_df2, color = "red", size = 1) +
    geom_line(aes(x = terminal, y = pred), data = ss_pred_df6, color = "green", size = 1) +
    geom_line(aes(x = terminal, y = pred), data = ss_pred_df10, color = "orange", size = 1) +
    geom_line(aes(x = terminal, y = pred), data = ss_pred_df20, color = "black", size = 1) +
    theme_bw()

```

???From the above model, we can observe that the degrees of freedom from GCV is `r round(ss_fit2$df, 3)`, with the smoothing parameter of `r round(ss_fit2$spar, 3)`, and $\lambda$ of `r round(ss_fit2$lambda, 3)`.


Describe the results obtained...................

```{r}

```

### Part c
Fit a generalized additive model (GAM) using all the predictors. Plot the results and explain your findings.

```{r}

gam_fit1 = gam(outstate ~ terminal+apps+accept+enroll+top10perc+top25perc+f_undergrad+p_undergrad+room_board+books+personal+ph_d+s_f_ratio, data = college_data)

gam_fit2 = gam(outstate ~ s(terminal)+apps+accept+enroll+top10perc+top25perc+f_undergrad+p_undergrad+room_board+books+personal+ph_d+s_f_ratio, data = college_data)

anova(gam_fit1, gam_fit2, test = "F")  # go with gam_fit2

plot(gam_fit2)
```

The degree of freedom obtained by GCV method is 3.35.

```{r gam_with_caret}

gam.fit <- train(x, y,
method = "gam",
tuneGrid = data.frame(method = "GCV.Cp", select = c(TRUE,FALSE)),
trControl = control)
gam.fit$bestTune

plot(gam.fit)
```


Describe the results obtained...................

### Part d
Fit a multivariate adaptive regression spline (MARS) model using all the predictors. Report the final model. Present the partial dependence plot of an arbitrary predictor in your final model.

First, we need to perform a grid search to identify the optimal combination of two tuning parameters (i.e degree of interactions and the number of retained terms) that minimize prediction error

```{r}

mars_grid = expand.grid(degree = 1:2,
                        nprune = 2:10)
set.seed(1)

mars_fit = train(x, y, method = "earth",
                tuneGrid = mars_grid,
                trControl = control)

ggplot(mars_fit)  ## ?! 10?? shouldn't I go further since 10 is a boundary value?
mars_fit$bestTune
coef(mars_fit$finalModel) # final model
```

We can create partial dependence plots (PDPs) for perc_alumni:
```{r PDP}

p1 = partial(mars_fit, pred.var = c("perc_alumni"), grid.resolution = 10) %>% autoplot()
```
